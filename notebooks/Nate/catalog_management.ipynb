{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catalog Wrangling Exercise  \n",
    "*:auth: Nate Stevens (PNSN)*\n",
    "\n",
    "In this exercise we'll use ObsPy and ObsPlus to create a highly translatable earthquake  \n",
    "catalog of located events from our analyses and those in the USGS Comprehensive Catalog  \n",
    "(ComCat) and do some quick intercomparisons between the two. Finally we'll save these  \n",
    "catalogs into a variety of standardized formats (schema) that are easy to re-load and  \n",
    "re-analyze with ObsPy and Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from obspy import read_events, UTCDateTime\n",
    "import obsplus\n",
    "from obspy.geodetics import gps2dist_azimuth, kilometer2degrees\n",
    "from obspy.clients.fdsn import Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make sure this points at wherever you saved your HypoDD outputs\n",
    "ROOT = Path.cwd()\n",
    "DATA = ROOT/'data'\n",
    "CATD = ROOT/'catalog_files'\n",
    "os.makedirs(str(CATD), exist_ok=True)\n",
    "print(f'The data directory is registered as {DATA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HypoDD output into an ObsPy `Catalog` object\n",
    "flist = glob(str(DATA/'*.pha'))\n",
    "for _e, _f in enumerate(flist):\n",
    "    if _e == 0:\n",
    "        cat = read_events(_f)\n",
    "    else:\n",
    "        cat += read_events(_f)\n",
    "\n",
    "\n",
    "display(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ObsPlus to show a DataFrame representation of events (takes a little time)\n",
    "df_events = cat.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare this table the ORIGIN table in the ANSS schema\n",
    "\n",
    "https://ncedc.org/db/Documents/NewSchemas/PI/v1.6.4/PI.1.6.4/Content/Tbl_388b5374f81611d6bcce00c04f794c81.htm\n",
    "\n",
    "#### ...and look at all those empty fields, just waiting for you to populate them!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display our new table (conveniently formatted in nearly ANSS EVENT table format!)\n",
    "display(df_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Althought the ObsPlus documentation is sometimes sparese on examples, their coding is quite good!\n",
    "Let's turn all of our picks into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns out the *.pha I/O for ObsPy has a little bug, so we need to apply a small correction to assign network and station codes to the correct fields\n",
    "try:\n",
    "    df_picks = cat.arrivals_to_df()\n",
    "except:\n",
    "    for event in cat.events:\n",
    "        for pick in event.picks:\n",
    "            sn = pick.waveform_id.station_code\n",
    "            pick.waveform_id.station_code=sn.split('.')[0]\n",
    "            pick.waveform_id.network_code=sn.split('.')[1]\n",
    "    df_picks = cat.arrivals_to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare this to the ARRIVAL and ASSOCARO tables in the ANSS schema\n",
    "\n",
    "#### ARRIVAL\n",
    "https://ncedc.org/db/Documents/NewSchemas/PI/v1.6.4/PI.1.6.4/Content/Tbl_388b5400f81611d6bcce00c04f794c81.htm\n",
    "\n",
    "#### ASSOCARO (Association of Arrivals and Origins)\n",
    "https://ncedc.org/db/Documents/NewSchemas/PI/v1.6.4/PI.1.6.4/Content/Tbl_388b542ef81611d6bcce00c04f794c81.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_picks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we've populated an ObsPy Catalog object, we can write into a bunch of different formats\n",
    "\n",
    "QuakeML is a well-described, extensible schema for seismic event (meta)data exchange  \n",
    "https://quake.ethz.ch/quakeml \n",
    "\n",
    "- ObsPy saves `Catalog` objects in this format as default  \n",
    "\n",
    "**BUT** before you go saving everything as one big QuakeML file, be warned that they can get large and slow to read from disk.  \n",
    "\n",
    "You can find one of my past sins against easily accessible (albiet well formatted) data here:  \n",
    "https://zenodo.org/records/8393876\n",
    "\n",
    "\n",
    "Instead, let's put our catalog into a tidy directory structure with a client interface!  \n",
    "Another place where `ObsPlus` shines!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an event bank\n",
    "ebank = obsplus.EventBank(base_path=CATD/'EventBank',\n",
    "                          path_structure='{year}/{month}/{day}/{hour}',\n",
    "                          name_structure='{event_id_end}',\n",
    "                          format='quakeml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add events to eventbank, and take a look at your file directory!\n",
    "ebank.put_events(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a summary of events in your event bank\n",
    "display(ebank.read_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's prove to ourself that this EventBank thingy is persistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE the EventBank Object in our session\n",
    "del ebank\n",
    "try:\n",
    "    display(ebank)\n",
    "except NameError:\n",
    "    print('ebank object does not exist, as expected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize connection to the EventBank\n",
    "ebank = obsplus.EventBank(base_path=CATD/'EventBank')\n",
    "display(ebank)\n",
    "# Note that the `path_structure` or `name_structure` key-word arguments we defined are saved!\n",
    "print('Our Event Bank values')\n",
    "display(ebank.path_structure)\n",
    "display(ebank.name_structure)\n",
    "print('Default values')\n",
    "print('{year}/{month}/{day}')\n",
    "print('{time}_{event_id_short}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query a subset of events\n",
    "# Read the index (a pandas DataFrame)\n",
    "df_index = ebank.read_index()\n",
    "# Subset by origin times\n",
    "_df_index = df_index[(df_index.time >= pd.Timestamp('2022-12-20T20:00:00')) & (df_index.time <= pd.Timestamp('2022-12-20T21:40:00'))]\n",
    "# Get events from your event bank\n",
    "cat = ebank.get_events(event_id=_df_index.event_id.values)\n",
    "\n",
    "display(cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's modify some event metadata and submit it to our EventBank\n",
    "In this case, let's add distances and back-azimuths to associated phases  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's populate some source-receiver geometry information\n",
    "client = Client('IRIS')\n",
    "nets = ','.join(list(df_picks.network.unique()))\n",
    "stas = ','.join(list(df_picks.station.unique()))\n",
    "inv = client.get_stations(network=nets, station=stas, level='channel',starttime=UTCDateTime('20221220'), endtime=UTCDateTime('20221221'))\n",
    "\n",
    "# Use ObsPlus added methods to convert the inventory into a dataframe\n",
    "df_stations = inv.to_df()\n",
    "\n",
    "display(df_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the maximum azimuthal gap to each origin\n",
    "# Here's a starting point:\n",
    "\n",
    "# Iterate across events\n",
    "origin_gaps = []\n",
    "for event in cat.events:\n",
    "    # Iterate across origins\n",
    "    for origin in event.origins:\n",
    "        olon = origin.longitude\n",
    "        olat = origin.latitude\n",
    "        # Iterate across associated arrivals\n",
    "        bazs = set([])\n",
    "        for arrival in origin.arrivals:\n",
    "            # Get pick observations\n",
    "            pick = arrival.pick_id.get_referred_object()\n",
    "            # Get station location\n",
    "            network = pick.waveform_id.network_code\n",
    "            station = pick.waveform_id.station_code\n",
    "            _df_sta = df_stations[(df_stations.network==network) & (df_stations.station==station)][['station','network','latitude','longitude']]\n",
    "            try:\n",
    "                slon = _df_sta.longitude.values[0]\n",
    "                slat = _df_sta.latitude.values[0]\n",
    "            except:\n",
    "                continue\n",
    "            # Get distances\n",
    "            dist_m, seaz, esaz = gps2dist_azimuth(slat, slon, olat, olon)\n",
    "            # Convert distance to degrees\n",
    "            arrival.distance = kilometer2degrees(dist_m*1e-3)\n",
    "            # Assign back-azimuth\n",
    "            arrival.azimuth = esaz\n",
    "\n",
    "## A task for the HACK-A-THON, get azimuthal gaps into your EventBank\n",
    "\n",
    "#             bazs.add(esaz)\n",
    "\n",
    "        \n",
    "#         # Calculate gaps\n",
    "#         bazs = list(bazs)\n",
    "#         bazs.sort()\n",
    "#         gaps = [bazs[_e+1] - bazs[_e] for _e in range(len(bazs)-1)] + [360 - bazs[-1] + bazs[0]]\n",
    "#         # Get maximum azimuthal gap\n",
    "#         maxgap = max(gaps)\n",
    "#         # associate with resourceID\n",
    "#         origin_gaps.append([origin.resource_id.id, maxgap])\n",
    "\n",
    "# # An exercise for users to incorporate 'gap' values into their preferred schema\n",
    "# display(pd.DataFrame(origin_gaps, columns=['resource_id','gap']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that the geometry data stuck\n",
    "display(cat.events[0].origins[0].arrivals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the catalog back to the event bank to update\n",
    "ebank.put_events(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete `cat` and re-load to prove to ourselves that the geometry information was saved\n",
    "del cat\n",
    "try:\n",
    "    display(cat)\n",
    "except NameError:\n",
    "    print('cat does not exist, as expected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load the sub-catalog\n",
    "cat = ebank.get_events(event_id = _df_index.event_id)\n",
    "display(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View that the geometry data persist on events we modified\n",
    "display(cat.events[0].origins[0].arrivals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the events and check an unmodified event\n",
    "cat = ebank.get_events()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display catalog (should see everything)\n",
    "display(cat)\n",
    "# Display the first event, which we did not modify\n",
    "display(cat.events[0].origins[0].arrivals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
