{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catalogging Exercise  \n",
    "*:auth: Nate Stevens (PNSN)*\n",
    "\n",
    "In this exercise we'll use ObsPy and ObsPlus to create a highly translatable earthquake\n",
    "catalog of located events from our analyses and those in the USGS Comprehensive Catalog\n",
    "(ComCat) and do some quick intercomparisons between the two. Finally we'll save these\n",
    "catalogs into a variety of standardized formats (schema) that are easy to re-load and\n",
    "re-analyze with ObsPy and Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from obspy import read_events, UTCDateTime\n",
    "import obsplus\n",
    "from obspy.geodetics import gps2dist_azimuth, kilometer2degrees\n",
    "from obspy.clients.fdsn import Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make sure this points at wherever you saved your HypoDD outputs\n",
    "ROOT = Path.cwd()\n",
    "DATA = ROOT/'data'\n",
    "CATD = ROOT/'catalog_files'\n",
    "os.makedirs(str(CATD), exist_ok=True)\n",
    "print(f'The data directory is registered as {DATA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HypoDD output into an ObsPy `Catalog` object\n",
    "flist = glob(str(DATA/'*.pha'))\n",
    "for _e, _f in enumerate(flist):\n",
    "    if _e == 0:\n",
    "        cat = read_events(_f)\n",
    "    else:\n",
    "        cat += read_events(_f)\n",
    "\n",
    "\n",
    "display(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ObsPlus to show a DataFrame representation of events (takes a little time)\n",
    "df_events = cat.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at all those empty fields, just waiting for you to populate them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display our new table (conveniently formatted in nearly ANSS EVENT table format!)\n",
    "display(df_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Althought the ObsPlus documentation is sometimes sparese on examples, their coding is quite good!\n",
    "Let's turn all of our picks into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns out the *.pha I/O reader has a little bug, so we need to apply a small correction to assign network and station codes to the correct fields\n",
    "try:\n",
    "    df_picks = cat.arrivals_to_df()\n",
    "except:\n",
    "    for event in cat.events:\n",
    "        for pick in event.picks:\n",
    "            sn = pick.waveform_id.station_code\n",
    "            pick.waveform_id.station_code=sn.split('.')[0]\n",
    "            pick.waveform_id.network_code=sn.split('.')[1]\n",
    "    df_picks = cat.arrivals_to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's populate some source-receiver geometry information\n",
    "client = Client('IRIS')\n",
    "nets = ','.join(list(df_picks.network.unique()))\n",
    "stas = ','.join(list(df_picks.station.unique()))\n",
    "inv = client.get_stations(network=nets, station=stas, level='channel',starttime=UTCDateTime('20221220'), endtime=UTCDateTime('20221221'))\n",
    "\n",
    "# Use ObsPlus added methods to convert the inventory into a dataframe\n",
    "df_stations = inv.to_df()\n",
    "\n",
    "display(df_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the maximum azimuthal gap to each origin\n",
    "# Here's a starting point:\n",
    "\n",
    "# Iterate across events\n",
    "origin_gaps = []\n",
    "for event in cat.events:\n",
    "    # Iterate across origins\n",
    "    for origin in event.origins:\n",
    "        olon = origin.longitude\n",
    "        olat = origin.latitude\n",
    "        # Iterate across associated arrivals\n",
    "        bazs = set([])\n",
    "        for arrival in origin.arrivals:\n",
    "            # Get pick observations\n",
    "            pick = arrival.pick_id.get_referred_object()\n",
    "            # Get station location\n",
    "            network = pick.waveform_id.network_code\n",
    "            station = pick.waveform_id.station_code\n",
    "            _df_sta = df_stations[(df_stations.network==network) & (df_stations.station==station)][['station','network','latitude','longitude']]\n",
    "            try:\n",
    "                slon = _df_sta.longitude.values[0]\n",
    "                slat = _df_sta.latitude.values[0]\n",
    "            except:\n",
    "                continue\n",
    "            # Get distances\n",
    "            dist_m, seaz, esaz = gps2dist_azimuth(slat, slon, olat, olon)\n",
    "            # Convert distance to degrees\n",
    "            arrival.distance = kilometer2degrees(dist_m*1e-3)\n",
    "            # Assign back-azimuth\n",
    "            arrival.azimuth = esaz\n",
    "            bazs.add(esaz)\n",
    "        # Calculate gaps\n",
    "        bazs = list(bazs)\n",
    "        bazs.sort()\n",
    "        gaps = [bazs[_e+1] - bazs[_e] for _e in range(len(bazs)-1)] + [360 - bazs[-1] + bazs[0]]\n",
    "        # Get maximum azimuthal gap\n",
    "        maxgap = max(gaps)\n",
    "        # associate with resourceID\n",
    "        origin_gaps.append([origin.resource_id.id, maxgap])\n",
    "\n",
    "display(pd.DataFrame(origin_gaps, columns=['resource_id','gap']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we've populated an ObsPy Catalog object, we can write into a bunch of different formats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
