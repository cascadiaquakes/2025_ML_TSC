{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# üß† Predicting Earthquake Origins with Graph Neural Networks\n",
    "\n",
    "**Author:** Lo√Øc Bachelot  \n",
    "**Goal:** This notebook demonstrates how to use a GNN to predict the 2D spatial origin of synthetic seismic events from graph-structured input data.\n",
    "\n",
    "---\n",
    "\n",
    "## üìò Overview\n",
    "\n",
    "Seismic events recorded across a geographic area generate time series data at multiple stations. To model the origin of these events:\n",
    "\n",
    "1. We treat each seismic station as a **node** in a graph.\n",
    "2. The **edges** represent relationships (e.g., geographic proximity).\n",
    "3. The **features** include both the station's location and the recorded signals.\n",
    "\n",
    "We‚Äôll walk through:\n",
    "- Creating synthetic data and graph structures\n",
    "- Building a GNN model (with attention-based pooling)\n",
    "- Training and evaluating the model\n",
    "- Visualizing predictions\n",
    "\n"
   ],
   "id": "e01dc4699e922b09"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üì¶ Imports and Setup\n",
    "We import PyTorch, PyTorch Geometric, and helper libraries used to build and train the GNN."
   ],
   "id": "f03802ef00b3ea64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.transforms import KNNGraph\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch.nn import Linear, Parameter, LeakyReLU, Conv2d, MaxPool1d\n",
    "from torch_geometric.nn import GCNConv, MessagePassing, MLP, GATv2Conv, global_mean_pool, GlobalAttention\n",
    "from scipy.spatial import distance\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import time\n"
   ],
   "id": "9d9300e5e1166f9d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üñºÔ∏è Visualization Helper Functions\n",
    "\n",
    "To better understand the structure of the input graphs and the behavior of the signal data, we define two visualization utilities:\n",
    "\n",
    "1. **`visualize_graph_torch`**  \n",
    "   This function draws the graph in 2D space:\n",
    "   - Nodes are colored based on a given feature (e.g., signal amplitude or attention score).\n",
    "   - Edges are shown as lines connecting nodes.\n",
    "   - The true event origin is marked with a red ‚ùå.\n",
    "   - If predictions are available, the model's estimated origin is shown with a blue ‚ùå.\n",
    "\n",
    "2. **`plot_signals_subplots_by_distance`**  \n",
    "   This function plots the signal recorded at each station in a separate subplot:\n",
    "   - Subplots are ordered by the station's distance from the origin.\n",
    "   - A red dashed line indicates the expected arrival time of the wave.\n",
    "   - This helps assess whether the signal aligns with physical expectations."
   ],
   "id": "5274abaccf1bf011"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def visualize_graph_torch(g, color, pred=False, ax=None, title=None):\n",
    "    \"\"\"\n",
    "    Visualize the graph structure with PyTorch Geometric graph object.\n",
    "\n",
    "    Args:\n",
    "        g (Data): Graph data object with edge_index, pos, and feature color\n",
    "        color (str): Node attribute key to use for coloring\n",
    "        pred (bool): If True, also plot predicted origin with blue cross\n",
    "        ax (matplotlib.axes.Axes, optional): If provided, draw into this axis\n",
    "        title (str, optional): Optional title to display above plot\n",
    "\n",
    "    Behavior:\n",
    "    - Nodes are colored by the specified feature (e.g., signal or attention score)\n",
    "    - Edges are drawn in blue\n",
    "    - True origin marked with red ‚ùå\n",
    "    - Prediction (if enabled) marked with blue ‚ùå\n",
    "    \"\"\"\n",
    "    created_fig = False\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        created_fig = True\n",
    "\n",
    "    # Plot edges\n",
    "    for edge in g.edge_index.T:\n",
    "        ax.plot(\n",
    "            [g.pos[edge[0]][0], g.pos[edge[1]][0]],\n",
    "            [g.pos[edge[0]][1], g.pos[edge[1]][1]],\n",
    "            color='blue', linewidth=1\n",
    "        )\n",
    "\n",
    "    # Node scatter with color\n",
    "    scatter = ax.scatter(\n",
    "        x=g.pos.T[0],\n",
    "        y=g.pos.T[1],\n",
    "        alpha=1,\n",
    "        c=g[color][:, 0],\n",
    "        s=150\n",
    "    )\n",
    "\n",
    "    # True origin\n",
    "    if hasattr(g, 'y') and g.y[0].numel() == 2:\n",
    "        ax.plot(g.y[0][0], g.y[0][1], 'rx', markersize=12, markeredgewidth=3)\n",
    "\n",
    "    # Predicted origin\n",
    "    if pred and hasattr(g, 'pred') and g.pred[0].numel() == 2:\n",
    "        ax.plot(g.pred[0][0], g.pred[0][1], 'bx', markersize=12, markeredgewidth=3)\n",
    "\n",
    "    # Title if given\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    # Clean axes\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Legend for coloring only once if top-level figure\n",
    "    if created_fig:\n",
    "        legend1 = ax.legend(*scatter.legend_elements(), loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        ax.add_artist(legend1)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_signals_subplots_by_distance(data, velocity=0.5, sampling_rate=1.0, title=\"Signals by distance to origin\"):\n",
    "    \"\"\"\n",
    "    Plot each station's signal in its own subplot, ordered by distance to origin,\n",
    "    with vertical lines showing the arrival time of the wavefront.\n",
    "\n",
    "    Args:\n",
    "        data (Data): PyG Data object with:\n",
    "            - pos: [num_nodes, 2]\n",
    "            - signal: [num_nodes, SIGNAL_SIZE]\n",
    "            - y: [1, 2] or [2] for origin location\n",
    "        velocity (float): Wave propagation speed (units per second)\n",
    "        sampling_rate (float): Sample rate (Hz)\n",
    "        title (str): Title of the figure\n",
    "    \"\"\"\n",
    "    pos = data.pos.cpu().numpy()\n",
    "    signals = data.signal.cpu().numpy()\n",
    "    origin = data.y.squeeze().cpu().numpy()\n",
    "\n",
    "    num_nodes = pos.shape[0]\n",
    "\n",
    "    # Compute distances from origin and convert to sample index\n",
    "    distances = np.array([distance.euclidean(origin, pos[i].tolist()) for i in range(num_nodes)])\n",
    "    arrival_samples = (distances / velocity * sampling_rate).astype(int)\n",
    "    sort_idx = np.argsort(distances)\n",
    "\n",
    "    # Plot one subplot per station\n",
    "    fig, axs = plt.subplots(num_nodes, 1, figsize=(10, 2 * num_nodes), sharex=True)\n",
    "    for i, idx in enumerate(sort_idx):\n",
    "        ax = axs[i]\n",
    "        signal = signals[idx]\n",
    "\n",
    "        ax.plot(np.arange(len(signal)), signal, color='black', linewidth=1)\n",
    "        ax.axvline(arrival_samples[idx], color='red', linestyle='--', linewidth=1, label='arrival')\n",
    "        ax.set_ylabel(f\"{distances[idx]:.2f}\", rotation=0, labelpad=25)\n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "    axs[-1].set_xlabel(\"Time (samples)\")\n",
    "    fig.suptitle(title, fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "    plt.show()"
   ],
   "id": "43f857905194a488"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üìà Synthetic Dataset Creation\n",
    "\n",
    "We simulate synthetic graph-based seismic data to train our Graph Neural Network (GNN). Each graph represents a seismic network where:\n",
    "\n",
    "- **Nodes** are seismic stations with 2D spatial coordinates.\n",
    "- **Edges** are created later based on k-nearest neighbors or distance.\n",
    "- **Signals** at each station are generated as noisy sine waves, delayed in time based on the distance to a hidden origin (the earthquake location).\n",
    "- **The target (`y`)** for each graph is the 2D coordinate of the origin ‚Äî the same for all nodes.\n",
    "\n",
    "#### üß™ Signal Generation Parameters:\n",
    "- **`nb_nodes ‚àà [10, 15]`**: Number of seismic stations per graph.\n",
    "- **`origin ‚àà [0, 6]¬≤`**: The true epicenter is sampled randomly in a 6√ó6 unit grid.\n",
    "- **`velocity = 0.5 units/sec`**: Controls how fast the signal propagates from the origin.\n",
    "- **`sampling_rate = 1.0 Hz`**: Defines the number of samples per unit of time.\n",
    "- **`noise_std = 0.1`**: Gaussian noise is added to simulate real-world signal variation.\n",
    "- **`SIGNAL_SIZE`**: Total number of samples in the signal window (e.g., 100).\n",
    "\n",
    "#### üåÄ How are signals delayed?\n",
    "The signal at each node starts with random noise. Then:\n",
    "- The time delay is computed as `distance / velocity`\n",
    "- Converted to a sample index: `delay_samples = delay * sampling_rate`\n",
    "- A sine wave is inserted at this delayed position in the signal\n",
    "\n",
    "This creates a physically intuitive training signal: stations farther from the source receive the waveform later in time.\n",
    "\n",
    "This setup allows the GNN to learn to **infer the origin coordinates** purely from the spatial pattern of waveform arrivals and features across nodes.\n"
   ],
   "id": "2f5ce3d61369aeaa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def add_edge_weight(g):\n",
    "    \"\"\"\n",
    "    Compute edge weights based on inverse distance between nodes.\n",
    "\n",
    "    This function adds an 'edge_weight' attribute to each graph,\n",
    "    calculated as 1 / (distance + 1) to ensure numerical stability.\n",
    "\n",
    "    Args:\n",
    "        g (Data): PyG graph with 'pos' and 'edge_index'\n",
    "\n",
    "    Returns:\n",
    "        Data: Modified graph with 'edge_weight'\n",
    "    \"\"\"\n",
    "    edge_weight = []\n",
    "    for edge in g.edge_index.T:\n",
    "        node_a, node_b = g.pos[edge[0]], g.pos[edge[1]]\n",
    "        dist = distance.euclidean((node_a[0], node_a[1]), (node_b[0], node_b[1]))\n",
    "        edge_weight.append(1 / (dist + 1))  # add 1 to avoid division by zero\n",
    "    g.edge_weight = torch.tensor(np.array(edge_weight)).type(torch.FloatTensor)\n",
    "    return g\n",
    "\n",
    "\n",
    "class SinOriginDataset(InMemoryDataset):\n",
    "    \"\"\"\n",
    "    Synthetic dataset for training GNNs to predict origin locations.\n",
    "\n",
    "    Each graph in the dataset includes:\n",
    "    - Randomly placed nodes in 2D space.\n",
    "    - Sine wave signals at each node, delayed by distance from a hidden origin.\n",
    "    - A regression target: the origin coordinates.\n",
    "\n",
    "    Args:\n",
    "        root (str): Root directory to save the processed data\n",
    "        nb_graph (int): Number of synthetic graphs to generate\n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform=None, pre_transform=None, nb_graph=10):\n",
    "        self.nb_graph = nb_graph\n",
    "        super(SinOriginDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0], weights_only=False)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        # No raw input files; data is generated from scratch\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "\n",
    "    def process(self):\n",
    "        data_list = []\n",
    "\n",
    "        # Dataset parameters\n",
    "        frequency = 1.0        # Hz\n",
    "        velocity = 0.5         # wave speed\n",
    "        sampling_rate = 1.0    # Hz\n",
    "        noise_std = 0.1        # Gaussian noise level\n",
    "\n",
    "        # Base sine wave used in signal synthesis\n",
    "        base_sine_wave = np.sin(np.arange(SIGNAL_SIZE))\n",
    "\n",
    "        for _ in range(self.nb_graph):\n",
    "            nb_nodes = np.random.randint(10, 15)  # Graph size\n",
    "            pos = torch.tensor(np.random.uniform(0, 6, size=(nb_nodes, 2)), dtype=torch.float)  # Node positions\n",
    "            origin = np.random.randint(0, 6, size=2)  # True origin\n",
    "            origin_tensor = torch.tensor(origin, dtype=torch.float)\n",
    "\n",
    "            signal_list = []\n",
    "            for i in range(nb_nodes):\n",
    "                dist = distance.euclidean(origin, pos[i].tolist())\n",
    "                delay = dist / velocity\n",
    "                delay_samples = int(delay * sampling_rate)\n",
    "\n",
    "                # Start with noise\n",
    "                waveform = np.random.normal(0, noise_std, size=SIGNAL_SIZE)\n",
    "\n",
    "                # Add delayed sine wave if within bounds\n",
    "                if delay_samples < SIGNAL_SIZE:\n",
    "                    insert_length = SIGNAL_SIZE - delay_samples\n",
    "                    waveform[delay_samples:] += base_sine_wave[:insert_length]\n",
    "\n",
    "                signal_list.append(waveform)\n",
    "\n",
    "            signal = torch.tensor(np.array(signal_list), dtype=torch.float32).reshape(nb_nodes, SIGNAL_SIZE)\n",
    "            g = Data(pos=pos, signal=signal, y=origin_tensor.unsqueeze(0))  # y shape: (1, 2)\n",
    "            data_list.append(g)\n",
    "\n",
    "        # Apply graph transformations if provided (e.g., KNN, edge weights)\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "            data_list = [add_edge_weight(data) for data in data_list]\n",
    "\n",
    "        # Save to disk\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ],
   "id": "aeb14dbdee42fe29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SIGNAL_SIZE = 20\n",
    "NB_GRAPHS = 1000\n",
    "\n",
    "raw_dataset = SinOriginDataset(root=\"./sin_train\", pre_transform=KNNGraph(k=5, loop=False, force_undirected=True), \n",
    "                       nb_graph=NB_GRAPHS)\n",
    "raw_dataset"
   ],
   "id": "e89dd0443df72fdf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üîç Exploring a Graph Sample\n",
    "\n",
    "Let‚Äôs take a look at one sample from our synthetic dataset to understand its structure.\n",
    "\n",
    "PyTorch Geometric stores each graph in a `Data` object. Here‚Äôs what each attribute means:\n",
    "\n",
    "- **`y=[1, 2]`**: The target ‚Äî the 2D coordinates of the true origin (shared by all nodes in the graph).\n",
    "- **`pos=[13, 2]`**: The 2D spatial positions of 13 nodes (i.e., seismic stations).\n",
    "- **`signal=[13, 20]`**: Each node has a 1D signal of length 20 (e.g., amplitude over time).\n",
    "- **`edge_index=[2, 74]`**: The graph has 74 directed edges represented as source/target pairs.\n",
    "- **`edge_weight=[74]`**: Weights for each edge, inversely proportional to spatial distance.\n",
    "\n",
    "This compact format allows the GNN to process signals in a way that respects the spatial relationships between nodes."
   ],
   "id": "af01a7be12e6ff16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = raw_dataset[0]\n",
    "data"
   ],
   "id": "b19bb06c37e4327d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "visualize_graph_torch(data, color='signal')",
   "id": "d5918a170b14823f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_signals_subplots_by_distance(data)",
   "id": "c4bb406c579deb06"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üîÑ Target Normalization\n",
    "\n",
    "Before training the model, we normalize the target coordinates (i.e., the true origin) to fall within a standard range.\n",
    "\n",
    "This is a common preprocessing step in regression problems, especially when using neural networks, because:\n",
    "- It helps with training stability and convergence.\n",
    "- Activations remain within consistent ranges.\n",
    "- The network doesn't need to \"learn\" scale information from scratch.\n",
    "\n",
    "We define a wrapper class `NormalizeTargetsWrapper` that rescales the target `y` values from their original coordinate bounds (e.g., [0, 6]) to the range **[-1, 1]**. This normalized range works well with activation functions like `tanh`.\n",
    "\n",
    "The class also includes a `denormalize()` method, which maps predictions back to the original coordinate space for evaluation and visualization."
   ],
   "id": "6324fa29848e46a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class NormalizeTargetsWrapper(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Wraps a PyG dataset to normalize `y` from [min_val, max_val] ‚Üí [-1, 1].\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, min_val, max_val):\n",
    "        self.dataset = dataset\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx].clone()\n",
    "        # scale from [min, max] to [-1, 1]\n",
    "        data.y = 2 * (data.y - self.min_val) / (self.max_val - self.min_val) - 1\n",
    "        return data\n",
    "\n",
    "    def denormalize(self, norm_y):\n",
    "        # scale back from [-1, 1] to [min, max]\n",
    "        return 0.5 * (norm_y + 1) * (self.max_val - self.min_val) + self.min_val"
   ],
   "id": "119e16ad37c669de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "normalized_dataset = NormalizeTargetsWrapper(raw_dataset, min_val=0, max_val=6)",
   "id": "25c495a85c4833ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Train/Validation/Test Split and Batching\n",
    "\n",
    "We split the dataset into three parts:\n",
    "- **50%** for training\n",
    "- **40%** of the remaining for validation\n",
    "- **10%** for testing\n",
    "\n",
    "Using `torch_geometric.loader.DataLoader`, we then batch graphs together for efficient training.\n",
    "\n",
    "#### üß± How batching works in PyTorch Geometric:\n",
    "Unlike image datasets, where each batch is a simple tensor stack, in **PyG**, batching involves:\n",
    "- Merging node and edge attributes from multiple graphs\n",
    "- Tracking which nodes belong to which graph using a `batch` vector\n",
    "- Allowing global pooling operations like `GlobalAttention` to work on per-graph basis\n",
    "\n",
    "Each batch now behaves like a single big disconnected graph, where GNN layers operate seamlessly across all examples.\n",
    "\n",
    "We set `batch_size=64` for all splits and enable shuffling only for training."
   ],
   "id": "8cfa6cb37f8dbcb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dataset, val_dataset = train_test_split(normalized_dataset, train_size=0.5, random_state=42)\n",
    "val_dataset, test_dataset = train_test_split(val_dataset, train_size=0.8, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "print(f\"nb graph train ds= {len(train_dataset)}, nb graph val ds= {len(val_dataset)}, nb graph test ds= {len(test_dataset)}\")"
   ],
   "id": "b1a9ac83e7092fd6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üß† GNN Model Definition: MLPNet\n",
    "\n",
    "We now define our **graph neural network** model, `MLPNet`, which predicts the origin coordinates of a seismic event from the structure and signals of a graph.\n",
    "\n",
    "### üèóÔ∏è Architecture Overview:\n",
    "\n",
    "1. **Input Features**:  \n",
    "   We concatenate each node‚Äôs 2D position with its signal vector.\n",
    "\n",
    "2. **MLP Encoder (`mlp_in`)**:  \n",
    "   A multi-layer perceptron (MLP) maps the concatenated input to a hidden representation.\n",
    "\n",
    "3. **Graph Attention Layers (`conv1`, `conv2`)**:  \n",
    "   Two `GATv2Conv` layers apply self-attention across neighboring nodes, using edge weights (inversely proportional to distance).  \n",
    "   > üîÅ *Note:* Only `conv1` is used here; `conv2` is commented out, for model simplification, but showing the possibility to extend the number of message passing layers.\n",
    "\n",
    "4. **MLP Decoder (`mlp_out`)**:  \n",
    "   Another MLP refines node embeddings after message passing.\n",
    "\n",
    "5. **Global Attention Pooling (`att_pool`)**:  \n",
    "   Aggregates node features into a single graph-level vector using learnable attention weights (via `GlobalAttention`).\n",
    "\n",
    "6. **Final Linear Output (`out_linear`)**:  \n",
    "   Predicts a 2D coordinate from the pooled graph representation, constrained to **[-1, 1]** via `tanh()`.\n",
    "\n",
    "### üì§ Output:\n",
    "- A single 2D coordinate per graph, representing the model‚Äôs **normalized prediction of the origin**.\n",
    "\n",
    "This architecture combines local (node-level) feature transformations with global (graph-level) aggregation, making it well-suited for spatial inference tasks like epicenter localization.\n"
   ],
   "id": "bb414f9a01cddc93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MLPNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    GNN model with MLP ‚Üí 2x GATv2Conv ‚Üí MLP for graph-level origin prediction.\n",
    "\n",
    "    Args:\n",
    "        channels_x (int): Positional input features per node.\n",
    "        channels_y (int): Signal features per node.\n",
    "        hidden_channels (int): Hidden dimension.\n",
    "        dropout (float): Dropout probability.\n",
    "        self_loops (bool): Whether to add self-loops to GATv2Conv.\n",
    "\n",
    "    Output:\n",
    "        Tensor of shape (batch_size, 2), normalized origin coordinates (in [-1, 1]).\n",
    "    \"\"\"\n",
    "    def __init__(self, channels_x, channels_y, hidden_channels=128, dropout=0.3, self_loops=True):\n",
    "        super(MLPNet, self).__init__()\n",
    "        torch.manual_seed(1234)\n",
    "\n",
    "        self.mlp_in = MLP([channels_x + channels_y, 64, hidden_channels])\n",
    "\n",
    "        self.conv1 = GATv2Conv(\n",
    "            in_channels=hidden_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            heads=2,\n",
    "            edge_dim=1,\n",
    "            add_self_loops=self_loops,\n",
    "            concat=True\n",
    "        )\n",
    "\n",
    "        self.conv2 = GATv2Conv(\n",
    "            in_channels=hidden_channels * 2,  # output of conv1 with 2 heads\n",
    "            out_channels=hidden_channels,\n",
    "            heads=2,\n",
    "            edge_dim=1,\n",
    "            add_self_loops=self_loops,\n",
    "            concat=True\n",
    "        )\n",
    "\n",
    "        self.mlp_out = MLP([hidden_channels * 2, 64], act=nn.LeakyReLU(), dropout=dropout)\n",
    "\n",
    "        self.att_pool = GlobalAttention(\n",
    "            gate_nn=torch.nn.Sequential(\n",
    "                nn.Linear(64, 32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32, 1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.out_linear = Linear(64, 2)\n",
    "        \n",
    "    def forward(self, pos, signal, edge_index, edge_weight, batch=None):\n",
    "        x = torch.cat([pos, signal], dim=-1)\n",
    "        x = self.mlp_in(x)\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        # x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.mlp_out(x)\n",
    "\n",
    "        if batch is None:\n",
    "            batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "\n",
    "        graph_repr = self.att_pool(x, batch)\n",
    "        return self.out_linear(graph_repr).tanh()"
   ],
   "id": "bbdb7aeea54d206a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üöÄ Training Loop\n",
    "\n",
    "This section defines the training and validation routines for our GNN model, as well as a simple early stopping mechanism."
   ],
   "id": "261a9ada7c8e89fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üõ†Ô∏è Helper Functions\n",
    "\n",
    "Before starting the main loop, we define:\n",
    "\n",
    "1. **`EarlyStopper`**  \n",
    "   A utility class to stop training when the validation loss plateaus. It tracks the lowest validation loss seen and stops training if no improvement is observed for a specified number of epochs (`patience`).\n",
    "\n",
    "2. **`train()`**  \n",
    "   Runs one full training epoch:\n",
    "   - Iterates over batched graphs\n",
    "   - Computes predictions and loss\n",
    "   - Updates model weights using backpropagation\n",
    "\n",
    "3. **`validation()`**  \n",
    "   Evaluates the model on a validation set without updating weights. This is used to monitor overfitting and trigger early stopping.\n",
    "\n",
    "> ‚ÑπÔ∏è Both `train()` and `validation()` rely on:\n",
    "- The global `model`, `optimizer`, and `criterion`\n",
    "- Batched data from `torch_geometric.loader.DataLoader`\n",
    "- `.to(device)` to move data to the appropriate compute device (e.g., GPU)"
   ],
   "id": "9fd62b18704dabfd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class EarlyStopper:\n",
    "    \"\"\"\n",
    "    A class for early stopping the training process when the validation loss stops improving.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "def train(dataloader, device):\n",
    "    model.train()\n",
    "    mean_loss = 0\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(data.pos, data.signal, data.edge_index, data.edge_weight, data.batch)  # ‚Üí shape [num_graphs, 2]\n",
    "\n",
    "        # Check shape of target\n",
    "        assert data.y.shape == pred.shape, f\"Expected y shape {pred.shape}, got {data.y.shape}\"\n",
    "\n",
    "        loss = criterion(pred, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        mean_loss += loss.item()\n",
    "    return mean_loss / len(dataloader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation(dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        pred = model(data.pos, data.signal, data.edge_index, data.edge_weight, data.batch)\n",
    "        loss = criterion(pred, data.y)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)"
   ],
   "id": "4317ec89a74aa3f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ‚öôÔ∏è Training Setup\n",
    "\n",
    "Before launching training:\n",
    "- We select a compute device (GPU if available).\n",
    "- Instantiate the `MLPNet` model.\n",
    "- Use **Mean Squared Error (MSE)** as the loss function ‚Äî ideal for continuous coordinate regression.\n",
    "- Choose the **Adam optimizer** with a learning rate of `1e-4`.\n",
    "- Initialize the `EarlyStopper` to monitor validation loss and prevent overfitting.\n",
    "- Set up a checkpointing path to save the best model based on validation performance."
   ],
   "id": "c75531ac071df1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = MLPNet(data.pos.shape[1], data.signal.shape[1], hidden_channels=64)\n",
    "\n",
    "criterion = torch.nn.MSELoss()  # Define loss criterion.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # Define optimizer.\n",
    "early_stopper = EarlyStopper(patience=1, min_delta=0.0)\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "PATH_CHECKPOINT = \"./checkpoint/best_origin_pred.pt\"\n",
    "model"
   ],
   "id": "2e95c108e260526e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üîÅ Training Loop\n",
    "\n",
    "The loop runs for up to **5000 epochs**, or until early stopping is triggered. At each epoch:\n",
    "- We compute and store the training and validation losses.\n",
    "- Save the model whenever a new best validation loss is observed.\n",
    "- Use `tqdm` to display a real-time progress bar with current losses.\n",
    "\n",
    "> üß† Note: Early stopping helps avoid unnecessary training once the model stops improving."
   ],
   "id": "7120217bf3b88347"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "start_time = time.perf_counter()\n",
    "nb_epoch = tqdm(range(5000))\n",
    "\n",
    "for epoch in nb_epoch:\n",
    "    loss_train.append(train(train_loader, device))\n",
    "    loss_val.append(validation(val_loader, device))\n",
    "    \n",
    "    if loss_val[-1] < best_loss:\n",
    "        best_loss = loss_val[-1]\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), PATH_CHECKPOINT)\n",
    "    if early_stopper.early_stop(loss_val[-1]):\n",
    "        print(f\"early stopping at epoch {epoch}: train loss={loss_train[-1]}, val loss={loss_val[-1]}\")\n",
    "        break\n",
    "    nb_epoch.set_postfix_str(f\"train loss={loss_train[-1]}, val loss={loss_val[-1]}\")"
   ],
   "id": "201944bcbf6f030a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(loss_train, label=\"Train\")\n",
    "plt.plot(loss_val, label = \"Validation\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ],
   "id": "7a19d212869004a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üìà Model Evaluation\n",
    "\n",
    "After training, we assess how well the model generalizes to unseen data.\n",
    "\n",
    "The evaluation process includes:\n",
    "\n",
    "1. **Load Best Model Checkpoint**  \n",
    "   We reload the model weights corresponding to the best validation loss during training. This ensures that we evaluate the most performant version of the model, not just the final state.\n",
    "\n",
    "2. **Visual Inspection on a Few Graphs**  \n",
    "   We make predictions on a small set of random graphs from the test set.  \n",
    "   - Visualize predicted vs true origin positions.\n",
    "   - Get an intuitive feel for typical prediction quality.\n",
    "\n",
    "3. **Full Test Set Prediction**  \n",
    "   We then predict on the entire test set to quantify performance over a larger sample.\n",
    "\n",
    "4. **Compute Simple Metrics**  \n",
    "   We calculate basic metrics such as:\n",
    "   - **Mean Absolute Error (MAE)** between predicted and true coordinates\n",
    "   - Optionally visualize prediction error distributions\n",
    "\n",
    "> üß† This evaluation allows both qualitative (plots) and quantitative (error metrics) understanding of model performance.\n"
   ],
   "id": "27c53610739e7ea4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# restore best model\n",
    "# PATH_CHECKPOINT = \"./checkpoint/best_origin_pred.pt\"\n",
    "model.load_state_dict(torch.load(PATH_CHECKPOINT))\n",
    "print(f\"best loss={best_loss}, model eval loss={validation(test_dataset, device)} at epoch {best_epoch}\")"
   ],
   "id": "5a916b84af352b53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üîç Visualizing Predictions on 9 Test Graphs\n",
    "\n",
    "To qualitatively evaluate the model‚Äôs spatial accuracy, we display predictions on 9 test graphs using a 3√ó3 grid.\n",
    "\n",
    "Each subplot shows:\n",
    "- The graph structure and node positions\n",
    "- Node coloring based on signal values\n",
    "- The **true origin** (red ‚ùå) and **predicted origin** (blue ‚ùå)\n",
    "- The per-sample **Euclidean error** in the title\n",
    "\n",
    "This visualization helps identify both successful and challenging prediction scenarios.\n"
   ],
   "id": "1b0fc95b102ee80f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i in range(9):\n",
    "    data = test_dataset[i].clone().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(data.pos, data.signal, data.edge_index, data.edge_weight, batch=None)\n",
    "\n",
    "    data.pred = normalized_dataset.denormalize(pred)\n",
    "    data.y = normalized_dataset.denormalize(data.y)\n",
    "    data.error = torch.norm(data.pred - data.y, dim=-1).unsqueeze(0)\n",
    "\n",
    "    ax = axs[i]\n",
    "    # Custom version of visualize_graph_torch that plots into a given `ax`\n",
    "    visualize_graph_torch(data, color=\"signal\", pred=True, ax=ax)\n",
    "    ax.set_title(f\"Sample {i} | Error: {data.error.item():.2f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "99093e1a7b470ffd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üìä Quantitative Evaluation and Error Distribution\n",
    "\n",
    "We compute a set of quantitative metrics over the full test set to assess the model's predictive accuracy.\n",
    "\n",
    "#### üßÆ Reported Metrics:\n",
    "- **MAE (Mean Absolute Error)** for X and Y separately\n",
    "- **Total MAE** across both dimensions\n",
    "- **RMSE (Root Mean Squared Error)** ‚Äî penalizes larger errors more heavily\n",
    "- **Mean Euclidean Error** ‚Äî distance between predicted and true origin\n",
    "- **Max Euclidean Error** ‚Äî worst-case prediction\n",
    "\n",
    "These metrics provide a robust summary of how well the model generalizes.\n",
    "\n",
    "#### üìâ Error Histogram:\n",
    "We also visualize the distribution of Euclidean errors across all test samples.\n",
    "\n",
    "A red dashed line shows the **expected error from a random guess**, providing a baseline reference.  \n",
    "The histogram reveals whether the model consistently predicts near the true origin ‚Äî or struggles in specific regions.\n"
   ],
   "id": "8e9fb08ecd64b300"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, test_loader, normalized_dataset, device):\n",
    "    \"\"\"\n",
    "    Evaluate model on the full test set and compute error metrics.\n",
    "\n",
    "    Returns:\n",
    "        Dict of evaluation metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    pred_all = []\n",
    "    true_all = []\n",
    "\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        pred = model(data.pos, data.signal, data.edge_index, data.edge_weight, data.batch)\n",
    "\n",
    "        pred_denorm = normalized_dataset.denormalize(pred)\n",
    "        true_denorm = normalized_dataset.denormalize(data.y)\n",
    "\n",
    "        pred_all.append(pred_denorm.cpu())\n",
    "        true_all.append(true_denorm.cpu())\n",
    "\n",
    "    pred_all = torch.cat(pred_all, dim=0)\n",
    "    true_all = torch.cat(true_all, dim=0)\n",
    "\n",
    "    abs_errors = torch.abs(pred_all - true_all)\n",
    "    euclidean_errors = torch.norm(pred_all - true_all, dim=1)\n",
    "\n",
    "    metrics = {\n",
    "        \"MAE_x\": abs_errors[:, 0].mean().item(),\n",
    "        \"MAE_y\": abs_errors[:, 1].mean().item(),\n",
    "        \"MAE_total\": abs_errors.mean().item(),\n",
    "        \"RMSE\": torch.sqrt(((pred_all - true_all) ** 2).mean()).item(),\n",
    "        \"Mean Euclidean Error\": euclidean_errors.mean().item(),\n",
    "        \"Max Euclidean Error\": euclidean_errors.max().item()\n",
    "    }\n",
    "\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: {v:.3f}\")\n",
    "\n",
    "    return metrics, pred_all, true_all\n",
    "\n",
    "def plot_error_histogram(pred_all, true_all, bounds=(0, 6), bins=30):\n",
    "    \"\"\"\n",
    "    Plot a histogram of Euclidean errors with optional random baseline.\n",
    "\n",
    "    Args:\n",
    "        pred_all (Tensor): shape [N, 2], model predictions (denormalized)\n",
    "        true_all (Tensor): shape [N, 2], true targets (denormalized)\n",
    "        bounds (tuple): min/max coordinate bounds for random baseline\n",
    "        bins (int): histogram bin count\n",
    "    \"\"\"\n",
    "    # Compute Euclidean errors\n",
    "    errors = torch.norm(pred_all - true_all, dim=1).numpy()\n",
    "\n",
    "    # Estimate expected error from random predictions in the same domain\n",
    "    num_samples = len(pred_all)\n",
    "    rand_preds = torch.rand_like(pred_all) * (bounds[1] - bounds[0]) + bounds[0]\n",
    "    rand_errors = torch.norm(rand_preds - true_all, dim=1).numpy()\n",
    "    expected_random_error = rand_errors.mean()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(errors, bins=bins, alpha=0.7, label=\"Model Prediction Error\")\n",
    "    plt.axvline(expected_random_error, color=\"red\", linestyle=\"--\", linewidth=2,\n",
    "                label=f\"Random baseline: {expected_random_error:.2f}\")\n",
    "    plt.xlabel(\"Euclidean Error\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Prediction Error Histogram\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "964dcc777f5817a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "metrics, pred_all, true_all = evaluate(model, test_loader, normalized_dataset, device)\n",
    "\n",
    "# reuse prediction and truth tensors\n",
    "plot_error_histogram(pred_all, true_all, bounds=(0, 6))"
   ],
   "id": "7b6d7664a93b02d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ‚úÖ Conclusion\n",
    "\n",
    "In this notebook, we built and evaluated a Graph Neural Network (GNN) to predict 2D origin coordinates from synthetic seismic-like signals distributed across a spatial graph.\n",
    "\n",
    "### üß† What We Did:\n",
    "- Generated a toy dataset of sine signals delayed by distance to a hidden origin.\n",
    "- Encoded both spatial (`pos`) and signal features for each node.\n",
    "- Used **GATv2Conv** layers and **Global Attention Pooling** to learn graph-level representations.\n",
    "- Normalized targets for stable training and evaluated with metrics like **MAE** and **RMSE**.\n",
    "- Visualized predictions at both the graph-level and dataset-level.\n",
    "\n",
    "### üìä What We Learned:\n",
    "- GNNs can effectively model spatial dependencies and delays in signal propagation.\n",
    "- Attention-based pooling enables flexible aggregation of node-level features.\n",
    "- Even in a simplified setting, **errors remain spatially structured** ‚Äî indicating areas where the model struggles (e.g., sparse graphs or boundary cases).\n",
    "\n",
    "### üß≠ Next Steps:\n",
    "- Try more complex synthetic scenarios: include signal polarity, noise bursts, or multi-event graphs.\n",
    "- Use real waveform datasets (e.g., from [SeisBench](https://github.com/seisbench/seisbench)) with station metadata.\n",
    "- Experiment with alternate architectures: **GINConv**, **Transformer-based pooling**, or **EdgeConv**.\n",
    "- Add uncertainty estimation or confidence bounds to predictions.\n",
    "\n",
    "> üöÄ GNNs are powerful tools for modeling geospatial and physical systems ‚Äî and this notebook is just a start!"
   ],
   "id": "2ef07ba6135aebc7"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
