{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c01d310df811f52",
   "metadata": {},
   "source": [
    "# 🌎 U-Net for Seismic Phase Picking\n",
    "\n",
    "**Author:** Loïc Bachelot  \n",
    "**Goal:** This notebook demonstrates how to define and train a U-Net model to detect seismic phases from waveform data.\n",
    "\n",
    "---\n",
    "\n",
    "## 📘 Overview\n",
    "\n",
    "Seismologists often need to detect the arrival times of P and S waves in continuous waveform recordings. These arrival times are crucial for locating earthquakes and understanding subsurface structures.\n",
    "\n",
    "In this notebook:\n",
    "1. We define a U-Net architecture inspired by [PhaseNet](https://github.com/wayneweiqiang/PhaseNet), adapted for 1D waveform inputs.\n",
    "2. The input is a windowed waveform.\n",
    "3. The output is a probability distribution over time indicating the likelihood of P and S wave arrivals.\n",
    "4. We visualize intermediate encoder/decoder outputs to understand how the network transforms the signal.\n",
    "\n",
    "The focus is on interpretability and pedagogical clarity — ideal for first-time users of deep learning in seismology.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba4e24546d96b4",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "We load a minimal subset of data required for model training. Detailed dataset explanations are handled in a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699a56460a00703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seisbench.data as sbd\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import seisbench.generate as sbg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f55262e4fe0925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the current directory\n",
    "data = sbd.WaveformDataset(\"./dataset_meso/\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80487817a8018fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.train()\n",
    "val = data.dev()\n",
    "test = data.test()\n",
    "phase_dict = {\n",
    "    \"trace_p_arrival_sample\": \"P\",\n",
    "    \"trace_pP_arrival_sample\": \"P\",\n",
    "    \"trace_P_arrival_sample\": \"P\",\n",
    "    \"trace_P1_arrival_sample\": \"P\",\n",
    "    \"trace_Pg_arrival_sample\": \"P\",\n",
    "    \"trace_Pn_arrival_sample\": \"P\",\n",
    "    \"trace_PmP_arrival_sample\": \"P\",\n",
    "    \"trace_pwP_arrival_sample\": \"P\",\n",
    "    \"trace_pwPm_arrival_sample\": \"P\",\n",
    "    \"trace_s_arrival_sample\": \"S\",\n",
    "    \"trace_S_arrival_sample\": \"S\",\n",
    "    \"trace_S1_arrival_sample\": \"S\",\n",
    "    \"trace_Sg_arrival_sample\": \"S\",\n",
    "    \"trace_SmS_arrival_sample\": \"S\",\n",
    "    \"trace_Sn_arrival_sample\": \"S\",\n",
    "}\n",
    "model_labels = [\"P\", \"S\", \"noise\"]\n",
    "\n",
    "train_generator = sbg.GenericGenerator(train)\n",
    "val_generator = sbg.GenericGenerator(val)\n",
    "test_generator = sbg.GenericGenerator(test)\n",
    "\n",
    "# Define the augmentation pipeline used for training and validation\n",
    "augmentations = [\n",
    "    # Extract a window around a randomly chosen phase sample (P or S)\n",
    "    sbg.WindowAroundSample(\n",
    "        list(phase_dict.keys()), samples_before=3000, windowlen=6000,\n",
    "        selection=\"random\", strategy=\"variable\"\n",
    "    ),\n",
    "    \n",
    "    # If needed, randomly crop or pad the window to a fixed length\n",
    "    sbg.RandomWindow(windowlen=3001, strategy=\"pad\"),\n",
    "    \n",
    "    # Normalize waveform: remove mean and scale amplitude (peak normalization)\n",
    "    sbg.Normalize(demean_axis=-1, amp_norm_axis=-1, amp_norm_type=\"peak\"),\n",
    "    \n",
    "    # Convert data type to float32 for training\n",
    "    sbg.ChangeDtype(np.float32),\n",
    "    \n",
    "    # Convert phase pick times into soft labels using Gaussian curves\n",
    "    sbg.ProbabilisticLabeller(label_columns=phase_dict, model_labels=model_labels, sigma=30, dim=0)\n",
    "]\n",
    "\n",
    "# Define a simpler augmentation for test data (no cropping or shifting)\n",
    "test_augmentations = [\n",
    "    sbg.Normalize(demean_axis=-1, amp_norm_axis=-1, amp_norm_type=\"peak\"),\n",
    "    sbg.ChangeDtype(np.float32),\n",
    "    sbg.ProbabilisticLabeller(label_columns=phase_dict, model_labels=model_labels, sigma=30, dim=0)\n",
    "]\n",
    "\n",
    "# Add augmentations to each dataset split\n",
    "train_generator.add_augmentations(augmentations)\n",
    "val_generator.add_augmentations(augmentations)\n",
    "test_generator.add_augmentations(test_augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae04e4bdf0b2bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_generator[np.random.randint(len(train_generator))]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "axs = fig.subplots(2, 1, sharex=True, gridspec_kw={\"hspace\": 0, \"height_ratios\": [3, 1]})\n",
    "axs[0].plot(sample[\"X\"].T)\n",
    "axs[1].plot(sample[\"y\"].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0022ab3398a4d7",
   "metadata": {},
   "source": [
    "### Prepare data for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff4611476d6b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seisbench.util import worker_seeding\n",
    "\n",
    "batch_size = 256\n",
    "num_workers = 4  # The number of threads used for loading data\n",
    "\n",
    "train_loader = DataLoader(train_generator, batch_size=batch_size, shuffle=True, num_workers=num_workers, worker_init_fn=worker_seeding)\n",
    "val_loader = DataLoader(val_generator, batch_size=batch_size, shuffle=False, num_workers=num_workers, worker_init_fn=worker_seeding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fcaaa9cdac9fda",
   "metadata": {},
   "source": [
    "## U-Net Model Definition\n",
    "\n",
    "In this section, we define a **U-Net** architecture tailored for 1D seismic waveform data. This model is inspired by [**PhaseNet**](https://doi.org/10.1093/gji/ggy423), a deep learning approach that demonstrated strong performance in seismic phase picking.\n",
    "\n",
    "### 🧠 What is a U-Net?\n",
    "\n",
    "A **U-Net** is a type of convolutional neural network originally developed for biomedical image segmentation. It has since proven effective for many tasks involving **dense predictions**, including segmentation and signal labeling. The U-Net architecture is characterized by:\n",
    "\n",
    "- A **contracting path** (encoder) that captures context through convolution and downsampling,\n",
    "- An **expanding path** (decoder) that enables precise localization by upsampling,\n",
    "- **Skip connections** that bridge encoder and decoder layers at the same resolution, preserving high-resolution features.\n",
    "\n",
    "Here's the architecture of **PhaseNet**, which adapts this idea for **1D seismic signals**:\n",
    "\n",
    "![PhaseNet Architecture](attachment:aa4c8e0f-60a3-4b08-ba50-0d2bedf056ec.jpeg)\n",
    "\n",
    "> *Weiqiang Zhu & Gregory C. Beroza (2019), PhaseNet: a deep-neural-network-based seismic arrival-time picking method, GJI, [DOI:10.1093/gji/ggy423](https://doi.org/10.1093/gji/ggy423)*\n",
    "\n",
    "### 🧭 Why use a U-Net for Seismology?\n",
    "\n",
    "Seismic waveform analysis requires:\n",
    "- **Context awareness** to detect arrival patterns over time,\n",
    "- **Precise localization** of P and S phase arrivals,\n",
    "- **Multiscale feature extraction**, since phase arrivals can vary in shape and amplitude.\n",
    "\n",
    "A U-Net is especially suited for this because:\n",
    "- The **encoder** captures long-range dependencies in the waveform,\n",
    "- The **decoder** reconstructs fine-grained outputs (e.g., phase probability at each timestep),\n",
    "- **Skip connections** ensure no loss of detail during downsampling.\n",
    "\n",
    "This makes it a perfect fit for **dense, frame-by-frame classification** of seismic traces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e8fdb1050dc062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf24c45033dcca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the U-Net architecture\n",
    "# Cell 2: U-Net Building Blocks\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size, padding=padding),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet1D(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, features=[16, 32, 64, 128]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.downs = nn.ModuleList()  # Encoder blocks (downsampling path)\n",
    "        self.ups = nn.ModuleList()    # Decoder blocks (upsampling path)\n",
    "    \n",
    "        # ----- Encoder: Downsampling Path -----\n",
    "        # Each ConvBlock halves the temporal resolution via pooling (done in forward),\n",
    "        # and increases the number of feature channels.\n",
    "        for feat in features:\n",
    "            self.downs.append(ConvBlock(in_channels, feat))  # ConvBlock: Conv + ReLU + Conv + ReLU\n",
    "            in_channels = feat  # Update in_channels for the next block\n",
    "    \n",
    "        # ----- Bottleneck -----\n",
    "        # Deepest layer in the U-Net, connects encoder and decoder\n",
    "        self.bottleneck = ConvBlock(features[-1], features[-1]*2)\n",
    "    \n",
    "        # ----- Decoder: Upsampling Path -----\n",
    "        # Reverse features list for symmetrical decoder\n",
    "        rev_feats = features[::-1]\n",
    "        for feat in rev_feats:\n",
    "            # First upsample (via transposed convolution)\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose1d(feat*2, feat, kernel_size=2, stride=2)\n",
    "            )\n",
    "            # Then apply ConvBlock: input has double channels due to skip connection\n",
    "            self.ups.append(ConvBlock(feat*2, feat))\n",
    "    \n",
    "        # ----- Final Output Convolution -----\n",
    "        # 1x1 convolution to map to desired output channels (e.g., P, S, noise)\n",
    "        self.final_conv = nn.Conv1d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = F.max_pool1d(x, kernel_size=2)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_conn = skip_connections[idx//2]\n",
    "            if x.shape[-1] != skip_conn.shape[-1]:\n",
    "                x = F.pad(x, (0, skip_conn.shape[-1] - x.shape[-1]))\n",
    "            x = torch.cat((skip_conn, x), dim=1)\n",
    "            x = self.ups[idx+1](x)\n",
    "        x = self.final_conv(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "    def forward_intermediate(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass that returns intermediate features from encoder, bottleneck, and decoder.\n",
    "    \n",
    "        Returns:\n",
    "            dict of tensors: including skip layers, bottleneck, and decoder layers.\n",
    "        \"\"\"\n",
    "        features = {\"input\": x}\n",
    "        skip_connections = []\n",
    "    \n",
    "        # ----- Encoder -----\n",
    "        for i, down in enumerate(self.downs):\n",
    "            x = down(x)\n",
    "            features[f\"enc{i+1}\"] = x  # Save encoder output\n",
    "            skip_connections.append(x)\n",
    "            x = F.max_pool1d(x, kernel_size=2)\n",
    "    \n",
    "        # ----- Bottleneck -----\n",
    "        x = self.bottleneck(x)\n",
    "        features[\"bottleneck\"] = x\n",
    "        skip_connections = skip_connections[::-1]\n",
    "    \n",
    "        # ----- Decoder -----\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)  # upsampling\n",
    "            skip_conn = skip_connections[idx // 2]\n",
    "    \n",
    "            # Handle any size mismatch from pooling\n",
    "            if x.shape[-1] != skip_conn.shape[-1]:\n",
    "                x = F.pad(x, (0, skip_conn.shape[-1] - x.shape[-1]))\n",
    "    \n",
    "            x = torch.cat((skip_conn, x), dim=1)\n",
    "            x = self.ups[idx + 1](x)  # convolution after concatenation\n",
    "            features[f\"dec{idx//2 + 1}\"] = x\n",
    "    \n",
    "        # ----- Final Prediction -----\n",
    "        x = self.final_conv(x)\n",
    "        out = F.softmax(x, dim=1)\n",
    "        features[\"output\"] = out\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f582a8a5e5495767",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "This section covers two main components:\n",
    "\n",
    "### 🛠️ Helper Functions\n",
    "We define modular functions to handle training \n",
    "\n",
    "### 🔁 Training Loop\n",
    "We then orchestrate the training process:\n",
    "- Select device (CPU/GPU),\n",
    "- Initialize model and optimizer,\n",
    "- Define early stopping and checkpointing criteria,\n",
    "- Track training and validation losses,\n",
    "- Save the best model based on validation loss.\n",
    "\n",
    "The training loop uses the helper functions to process the data over multiple epochs, evaluate progress, and stop early if performance plateaus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad05cfebd1afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b336656581ec3483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def loss_fn(y_pred, y_true, eps=1e-5):\n",
    "    # vector cross entropy loss\n",
    "    h = y_true * torch.log(y_pred + eps)\n",
    "    h = h.mean(-1).sum(-1)  # Mean along sample dimension and sum along pick dimension\n",
    "    h = h.mean()  # Mean over batch axis\n",
    "    return -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932ac98b31c8ba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "class EarlyStopper:\n",
    "    \"\"\"\n",
    "    A class for early stopping the training process when the validation loss stops improving.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    patience : int, optional (default=1)\n",
    "        The number of epochs with no improvement in validation loss after which training will be stopped.\n",
    "    min_delta : float, optional (default=0)\n",
    "        The minimum change in the validation loss required to qualify as an improvement.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        \"\"\"\n",
    "        Check if the training process should be stopped.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        validation_loss : float\n",
    "            The current validation loss.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        stop : bool\n",
    "            Whether the training process should be stopped or not.\n",
    "        \"\"\"\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb1efe650345262",
   "metadata": {},
   "source": [
    "### Training and Evaluation Helpers\n",
    "\n",
    "To keep the training loop clean and modular, we define two helper functions:\n",
    "\n",
    "- `train_loop(...)`: Trains the model for one epoch using a given dataset and optimizer.\n",
    "- `test_loop(...)`: Evaluates the model on a validation or test set.\n",
    "\n",
    "This separation improves **code readability**, helps **avoid repetition**, and makes the notebook easier to maintain or adapt later (e.g., for different models or datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ddc39d4f099d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, dataloader, optimizer, debug=False):\n",
    "    \"\"\"\n",
    "    One epoch of training.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to train.\n",
    "        dataloader (DataLoader): Batches of training data.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer for updating model weights.\n",
    "\n",
    "    Returns:\n",
    "        float: Average loss over the epoch.\n",
    "    \"\"\"\n",
    "    mean_loss = 0\n",
    "    model.train()  # Set model to training mode\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    for batch_id, batch in enumerate(dataloader):\n",
    "        # Forward pass — model prediction\n",
    "        pred = model(batch[\"X\"].to(device))\n",
    "\n",
    "        # Compute the loss between prediction and ground truth\n",
    "        loss = loss_fn(pred, batch[\"y\"].to(device))\n",
    "\n",
    "        # Backward pass and optimizer update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging every 5 batches\n",
    "        if batch_id % 5 == 0:\n",
    "            loss_val = loss.item()\n",
    "            current = batch_id * batch[\"X\"].shape[0]\n",
    "            if debug:\n",
    "                print(f\"loss: {loss_val:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        mean_loss += loss_val\n",
    "\n",
    "    return mean_loss / size  # Return average loss for the epoch\n",
    "\n",
    "\n",
    "def test_loop(model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluation on validation or test data.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to evaluate.\n",
    "        dataloader (DataLoader): Batches of data.\n",
    "\n",
    "    Returns:\n",
    "        float: Average loss over the dataset (per sample).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X = batch[\"X\"].to(device)\n",
    "            y = batch[\"y\"].to(device)\n",
    "            pred = model(X)\n",
    "\n",
    "            loss = loss_fn(pred, y).item()\n",
    "            test_loss += loss * X.shape[0]  # scale back up by batch size\n",
    "            total_samples += X.shape[0]\n",
    "\n",
    "    return test_loss / total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89050bf61c459497",
   "metadata": {},
   "source": [
    "## Training Configuration\n",
    "\n",
    "Before training, we configure the computing device, model, optimizer, loss tracking, early stopping, and checkpointing.\n",
    "\n",
    "- **Device selection** ensures training runs on GPU if available.\n",
    "- **Model initialization** moves the model to the selected device.\n",
    "- **Adam optimizer** is commonly used for deep learning due to adaptive learning rates.\n",
    "- **Checkpointing** allows saving the best model during training.\n",
    "- **Early stopping** halts training when the validation loss stops improving to prevent overfitting.\n",
    "- **Logging** prints progress and training setup details for transparency and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf77ded3ed8f5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device {device}\")\n",
    "model = UNet1D().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "nb_epoch = 100\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "best_loss = 100 # init at something super high so 1st eval is best\n",
    "best_epoch = 0\n",
    "early_stopper = EarlyStopper(patience=1, min_delta=0.0)\n",
    "model_name = \"phasenet_style\"\n",
    "PATH_CHECKPOINT = f\"./checkpoint/{model_name}.pt\"\n",
    "log_counter = 1\n",
    "\n",
    "print(\"\\n=== Training Configuration Recap ===\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Checkpoint Path: {PATH_CHECKPOINT}\")\n",
    "print(f\"Optimizer: Adam\")\n",
    "print(f\"Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
    "print(f\"Epochs: {nb_epoch}\")\n",
    "print(f\"Early Stopping Patience: {early_stopper.patience}\")\n",
    "print(f\"Early Stopping Min Delta: {early_stopper.min_delta}\")\n",
    "print(\"====================================\\n\")\n",
    "summary(model, input_size=(1, 3, 3001))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d9791c606fd310",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "The model is trained using a typical PyTorch training loop with the following components:\n",
    "\n",
    "- **Training and validation loss tracking**: The model is evaluated on both the training and validation set each epoch.\n",
    "- **Checkpointing**: The best model (with lowest validation loss) is saved automatically.\n",
    "- **Early stopping**: Training stops if the validation loss doesn't improve for a preset number of epochs, helping to avoid overfitting.\n",
    "- **Logging**: Progress is logged every few epochs, including the current and best losses and timing information.\n",
    "\n",
    "This setup ensures that the model is both efficient and robust during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6ba7e8f6adcb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with early stopping and checkpointing\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "print(f\"Training starting — number of epochs = {nb_epoch}\")\n",
    "\n",
    "for epoch in range(nb_epoch):\n",
    "    # Train on one epoch and record the training loss\n",
    "    loss_train.append(train_loop(model, train_loader, optimizer))\n",
    "    \n",
    "    # Evaluate on validation set and record the loss\n",
    "    loss_val.append(test_loop(model, val_loader))\n",
    "    \n",
    "    # If validation loss improves, save the model checkpoint\n",
    "    if loss_val[-1] < best_loss:\n",
    "        best_loss = loss_val[-1]\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), PATH_CHECKPOINT)  # Save best model\n",
    "\n",
    "    # Check early stopping condition (e.g., no improvement for N epochs)\n",
    "    if early_stopper.early_stop(loss_val[-1]):\n",
    "        print(f\"Early stopping at epoch {epoch}:\")\n",
    "        print(f\"  → Train loss = {loss_train[-1]:.6f}\")\n",
    "        print(f\"  → Val loss   = {loss_val[-1]:.6f}\")\n",
    "        break\n",
    "\n",
    "    # Logging every `log_counter` epochs\n",
    "    if epoch % log_counter == 0:\n",
    "        print(f\"Epoch {epoch}:\")\n",
    "        print(f\"  → Train loss = {loss_train[-1]:.6f}\")\n",
    "        print(f\"  → Val loss   = {loss_val[-1]:.6f}\")\n",
    "        print(f\"  → Best val loss = {best_loss:.6f} (epoch {best_epoch})\")\n",
    "        print(f\"  → Avg time per epoch = {(time.perf_counter() - start_time) / log_counter:.2f} sec\")\n",
    "        print(\"\\n#####################\\n\")\n",
    "        start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f83475674977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(f\"training finished, restoring best weights\")\n",
    "model.load_state_dict(torch.load(PATH_CHECKPOINT, map_location=device))\n",
    "print(f\"best loss={best_loss}, model eval loss={test_loop(model, val_loader)} at epoch {best_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8b6307eb3b6b4f",
   "metadata": {},
   "source": [
    "## Inference on Long Waveforms\n",
    "\n",
    "After training, we want to apply the model to long, continuous waveform data.\n",
    "\n",
    "Because the U-Net expects fixed-length input (e.g., 3001 samples), we use **sliding window inference** to break long waveforms into overlapping chunks, apply the model to each chunk, and then combine the outputs.\n",
    "\n",
    "Key steps:\n",
    "- `extract_sliding_windows(...)`: slices the waveform into overlapping windows.\n",
    "- `batched_sliding_inference(...)`: runs the model on all windows efficiently using batching, then recombines predictions.\n",
    "- `normalize_waveform(...)`: standard preprocessing to center and scale amplitude.\n",
    "\n",
    "This allows us to make **dense predictions** over time (e.g., probability of P or S arrivals at each time step) even on long signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e383fc5219847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sliding_windows(waveform, window_size=3001, stride=10):\n",
    "    \"\"\"\n",
    "    Slice the waveform into overlapping sliding windows.\n",
    "\n",
    "    Args:\n",
    "        waveform (np.ndarray): Array of shape (3, T) — 3 channels (Z, N, E).\n",
    "        window_size (int): Length of each window.\n",
    "        stride (int): Step size between windows.\n",
    "\n",
    "    Returns:\n",
    "        windows (np.ndarray): Shape (num_windows, 3, window_size)\n",
    "        indices (np.ndarray): Starting indices of each window\n",
    "    \"\"\"\n",
    "    C, T = waveform.shape\n",
    "    indices = np.arange(0, T - window_size + 1, stride)\n",
    "    windows = np.stack([waveform[:, i:i + window_size] for i in indices], axis=0)\n",
    "    return windows, indices\n",
    "\n",
    "\n",
    "def batched_sliding_inference(waveform, model, window_size=3001, stride=100, device=\"cpu\", batch_size=512):\n",
    "    \"\"\"\n",
    "    Perform model inference over a long waveform using overlapping sliding windows.\n",
    "\n",
    "    Args:\n",
    "        waveform (np.ndarray): Shape (3, T), raw waveform data.\n",
    "        model (torch.nn.Module): Trained model.\n",
    "        window_size (int): Length of each input window.\n",
    "        stride (int): Step between windows.\n",
    "        device (str): 'cpu' or 'cuda'.\n",
    "        batch_size (int): Number of windows per batch.\n",
    "\n",
    "    Returns:\n",
    "        probs (np.ndarray): Shape (3, T), class probabilities for each timestep.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    waveform = waveform.astype(np.float32)\n",
    "    \n",
    "    # Split waveform into overlapping windows\n",
    "    windows, indices = extract_sliding_windows(waveform, window_size, stride)\n",
    "    num_windows = len(windows)\n",
    "\n",
    "    # Initialize prediction buffer and count buffer\n",
    "    probs = np.zeros((3, waveform.shape[1]))\n",
    "    counts = np.zeros((waveform.shape[1],))\n",
    "\n",
    "    # Run model in batches over windows\n",
    "    for i in range(0, num_windows, batch_size):\n",
    "        batch = torch.tensor(windows[i:i + batch_size], dtype=torch.float32).to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(batch).cpu().numpy()  # shape: (B, 3, window_size)\n",
    "\n",
    "        # Aggregate overlapping predictions\n",
    "        for j, idx in enumerate(indices[i:i + batch_size]):\n",
    "            probs[:, idx:idx + window_size] += out[j]\n",
    "            counts[idx:idx + window_size] += 1\n",
    "\n",
    "    # Normalize by number of overlapping windows at each time step\n",
    "    counts[counts == 0] = 1  # avoid division by zero\n",
    "    probs /= counts\n",
    "\n",
    "    return probs\n",
    "\n",
    "\n",
    "def normalize_waveform(waveform):\n",
    "    \"\"\"\n",
    "    Normalize waveform: zero-mean and peak amplitude scaling.\n",
    "\n",
    "    Args:\n",
    "        waveform (np.ndarray): Shape (3, T), raw waveform.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Normalized waveform of same shape.\n",
    "    \"\"\"\n",
    "    waveform = waveform - np.mean(waveform, axis=-1, keepdims=True)\n",
    "    norm = np.max(np.abs(waveform), axis=-1, keepdims=True)\n",
    "    norm[norm == 0] = 1  # avoid division by zero\n",
    "    return waveform / norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87d1ce8f14a5de8",
   "metadata": {},
   "source": [
    "## Running Inference on Test Set\n",
    "\n",
    "We now evaluate the model on a set of test waveforms using the `batched_sliding_inference(...)` method defined earlier.\n",
    "\n",
    "Each waveform is:\n",
    "- **Normalized** using peak amplitude scaling,\n",
    "- **Processed in overlapping windows** by the model,\n",
    "- **Reconstructed into a full-length probability prediction**.\n",
    "\n",
    "We also collect metadata such as true labels and arrival times for later comparison and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e92ad8dc195874",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "number_samples = 20\n",
    "# Loop over number_samples test samples\n",
    "for i in tqdm(range(number_samples)):\n",
    "    # Use test_generator to get the full sample, including labels\n",
    "    sample = test_generator[i]\n",
    "    \n",
    "    # Extract waveform, true soft labels, and metadata\n",
    "    waveform = sample[\"X\"]  # Shape: (3, T)\n",
    "    true_labels = sample[\"y\"]  # Shape: (3, T), soft targets for P/S/Noise\n",
    "    meta = sample.get(\"meta\", test.get_sample(i)[1])  # Fall back to original metadata if needed\n",
    "\n",
    "    # Normalize waveform before feeding to model\n",
    "    waveform = normalize_waveform(waveform.astype(np.float32))\n",
    "\n",
    "    # Run sliding window inference on the waveform\n",
    "    start = time.time()\n",
    "    pred = batched_sliding_inference(waveform, model, device=device)\n",
    "    end = time.time()\n",
    "\n",
    "    # Collect results in a dictionary\n",
    "    all_results.append({\n",
    "        \"trace_id\": meta.get(\"trace_name\", f\"trace_{i}\"),\n",
    "        \"waveform\": waveform,\n",
    "        \"true_labels\": true_labels,\n",
    "        \"prediction\": pred,\n",
    "        \"p_arrival\": meta.get(\"trace_P_arrival_sample\"),\n",
    "        \"s_arrival\": meta.get(\"trace_S_arrival_sample\"),\n",
    "        \"meta\": meta,\n",
    "        \"inference_time\": end - start\n",
    "    })\n",
    "\n",
    "print(f\"Inference finished for the {number_samples} test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3532b0c92c86187",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = np.random.choice(all_results, 5, replace=False)\n",
    "\n",
    "for example in examples:\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(15, 8), sharex=True)\n",
    "    fig.suptitle(f\"Trace ID: {example['trace_id']}\", fontsize=16)\n",
    "\n",
    "    waveform = example[\"waveform\"]\n",
    "    pred = example[\"prediction\"]\n",
    "\n",
    "    axs[0].plot(waveform.T)\n",
    "    axs[0].set_ylabel(\"Waveform\")\n",
    "\n",
    "    axs[1].plot(pred.T)\n",
    "    axs[1].set_ylabel(\"Prediction\\n[Noise, P, S]\")\n",
    "\n",
    "    axs[2].set_title(\"Ground Truth Picks\")\n",
    "    axs[2].plot(pred.T[0]*0, \"gray\", alpha=0.2)  # zero baseline\n",
    "\n",
    "    if example[\"p_arrival\"] is not None:\n",
    "        axs[2].axvline(example[\"p_arrival\"], color=\"blue\", linestyle=\"--\", label=\"P arrival\")\n",
    "    if example[\"s_arrival\"] is not None:\n",
    "        axs[2].axvline(example[\"s_arrival\"], color=\"orange\", linestyle=\"--\", label=\"S arrival\")\n",
    "    \n",
    "    axs[2].legend()\n",
    "    axs[2].set_xlabel(\"Time [samples]\")\n",
    "    axs[2].set_ylabel(\"Pick\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee22334a4afbaa",
   "metadata": {},
   "source": [
    "## 🔍 Explore Encoded Layers (Windowed)\n",
    "\n",
    "To gain insight into what the U-Net is learning internally, we extract a 3001-sample window from a test waveform that includes P and S arrivals.\n",
    "\n",
    "We examine:\n",
    "- The original 3-channel waveform (Z, N, E),\n",
    "- The deepest bottleneck representation,\n",
    "- The final output probabilities for P, S, and Noise.\n",
    "\n",
    "We overlay the P and S arrival times across all plots to highlight how seismic phase information propagates through the network’s hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe23e8beb65a4652",
   "metadata": {},
   "source": [
    "### Visualizing Model Inference and Intermediate Features\n",
    "\n",
    "In this section, we extract a test window from the waveform that includes both P and S arrivals. We run the trained U-Net model on this window and visualize:\n",
    "\n",
    "1. **Input waveform**: Three channels (Z, N, E) with amplitude offset for clarity.\n",
    "2. **Bottleneck features**: A heatmap showing the compressed feature representation after the encoder.\n",
    "3. **Predictions vs. True Labels**: Model output probabilities for P, S, and Noise classes compared against the ground truth.\n",
    "\n",
    "Red and green vertical lines mark the P and S arrival times, respectively, allowing for visual evaluation of model accuracy.\n",
    "\n",
    "This type of visualization helps understand how the model transforms seismic data at different stages and assess the quality of its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf07cef190719856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Slice a test window that includes P and S arrivals ---\n",
    "start = 5000  # start index of the window\n",
    "sample = test_generator[0]\n",
    "waveform = sample[\"X\"][:, start:start+3001]\n",
    "true_labels = sample[\"y\"][:, start:start+3001]\n",
    "meta = sample.get(\"meta\", test.get_sample(0)[1])  # get metadata\n",
    "\n",
    "x = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "# --- 2. Run model with intermediate outputs ---\n",
    "features = model.forward_intermediate(x)\n",
    "input_wave = features[\"input\"].squeeze().cpu().detach().numpy()\n",
    "bottleneck = features[\"bottleneck\"].squeeze().cpu().detach().numpy()\n",
    "prediction = features[\"output\"].squeeze().cpu().detach().numpy()\n",
    "\n",
    "# --- 3. Setup figure ---\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# --- 4. Plot input waveform ---\n",
    "for i in range(3):\n",
    "    axes[0].plot(input_wave[i] + i * 2, label=f\"Channel {['Z', 'N', 'E'][i]}\")\n",
    "axes[0].set_title(\"Input Waveform\")\n",
    "axes[0].legend()\n",
    "\n",
    "# --- 5. Plot bottleneck features as heatmap with extended x-axis ---\n",
    "input_len = input_wave.shape[-1]\n",
    "extent = [0, input_len, 0, bottleneck.shape[0]]\n",
    "im = axes[1].imshow(bottleneck, aspect=\"auto\", cmap=\"viridis\", extent=extent)\n",
    "axes[1].set_title(\"Bottleneck Features\")\n",
    "axes[1].set_ylabel(\"Channels\")\n",
    "plt.colorbar(im, ax=axes[1], orientation=\"vertical\")\n",
    "\n",
    "# --- 6. Plot predictions vs. true labels ---\n",
    "labels = [\"P\", \"S\", \"Noise\"]\n",
    "for i in range(3):\n",
    "    axes[2].plot(prediction[i], label=f\"Pred {labels[i]}\", linestyle='-')\n",
    "    axes[2].plot(true_labels[i], label=f\"True {labels[i]}\", linestyle='--', alpha=0.5)\n",
    "axes[2].set_title(\"Prediction vs. True Labels\")\n",
    "axes[2].legend()\n",
    "axes[2].set_xlabel(\"Time (samples)\")\n",
    "\n",
    "# --- 7. Overlay P and S arrival lines (aligned with input time) ---\n",
    "p_arrival = meta.get(\"trace_P_arrival_sample\")\n",
    "s_arrival = meta.get(\"trace_S_arrival_sample\")\n",
    "\n",
    "if p_arrival is not None:\n",
    "    p_shifted = p_arrival - start\n",
    "    if 0 <= p_shifted < input_len:\n",
    "        for ax in axes:\n",
    "            ax.axvline(p_shifted, color=\"red\", linestyle=\"--\", label=\"P arrival\")\n",
    "if s_arrival is not None:\n",
    "    s_shifted = s_arrival - start\n",
    "    if 0 <= s_shifted < input_len:\n",
    "        for ax in axes:\n",
    "            ax.axvline(s_shifted, color=\"green\", linestyle=\"--\", label=\"S arrival\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e0308a77521262",
   "metadata": {},
   "source": [
    "## Comparing Early and Late Layers\n",
    "\n",
    "To better understand how the U-Net transforms seismic signals, we visualize:\n",
    "\n",
    "- The original input waveform,\n",
    "- The **first encoder layer output** (early, low-level features),\n",
    "- The **last decoder layer output** (just before final prediction),\n",
    "- The final prediction probabilities vs. true labels.\n",
    "\n",
    "We overlay the P and S arrival times to show how signal structures evolve through the network while still preserving alignment with the seismic event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd2b87d0bb7a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Get a test window that includes arrivals ---\n",
    "start = 5000\n",
    "sample = test_generator[0]\n",
    "waveform = sample[\"X\"][:, start:start+3001]\n",
    "true_labels = sample[\"y\"][:, start:start+3001]\n",
    "meta = sample.get(\"meta\", test.get_sample(0)[1])\n",
    "\n",
    "x = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "# --- 2. Run model and extract intermediate features ---\n",
    "features = model.forward_intermediate(x)\n",
    "input_wave = features[\"input\"].squeeze().cpu().detach().numpy()\n",
    "enc1 = features[\"enc1\"].squeeze().cpu().detach().numpy()\n",
    "bottleneck = features[\"bottleneck\"].squeeze().cpu().detach().numpy()\n",
    "dec_last = features[\"dec4\"].squeeze().cpu().detach().numpy()\n",
    "prediction = features[\"output\"].squeeze().cpu().detach().numpy()\n",
    "\n",
    "# --- 3. Plot input, enc1, dec_last, and output ---\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Plot input waveform\n",
    "for i in range(3):\n",
    "    axes[0].plot(input_wave[i] + i * 2, label=f\"Channel {['Z', 'N', 'E'][i]}\")\n",
    "axes[0].set_title(\"Input Waveform\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot encoder layer 1\n",
    "axes[1].imshow(enc1, aspect=\"auto\", cmap=\"viridis\", extent=[0, input_wave.shape[-1], 0, enc1.shape[0]])\n",
    "axes[1].set_title(\"First Encoder Layer (enc1)\")\n",
    "axes[1].set_ylabel(\"Channels\")\n",
    "\n",
    "# Plot last decoder layer\n",
    "axes[2].imshow(dec_last, aspect=\"auto\", cmap=\"viridis\", extent=[0, input_wave.shape[-1], 0, dec_last.shape[0]])\n",
    "axes[2].set_title(\"Last Decoder Layer (dec4)\")\n",
    "axes[2].set_ylabel(\"Channels\")\n",
    "\n",
    "# Plot predictions vs true labels\n",
    "labels = [\"P\", \"S\", \"Noise\"]\n",
    "for i in range(3):\n",
    "    axes[3].plot(prediction[i], label=f\"Pred {labels[i]}\", linestyle='-')\n",
    "    axes[3].plot(true_labels[i], label=f\"True {labels[i]}\", linestyle='--', alpha=0.5)\n",
    "axes[3].set_title(\"Prediction vs. True Labels\")\n",
    "axes[3].legend()\n",
    "axes[3].set_xlabel(\"Time (samples)\")\n",
    "\n",
    "# --- 4. Add vertical lines for P and S arrivals if within window ---\n",
    "p_arrival = meta.get(\"trace_P_arrival_sample\")\n",
    "s_arrival = meta.get(\"trace_S_arrival_sample\")\n",
    "\n",
    "if p_arrival is not None:\n",
    "    p_shifted = p_arrival - start\n",
    "    if 0 <= p_shifted < input_wave.shape[-1]:\n",
    "        for ax in axes:\n",
    "            ax.axvline(p_shifted, color=\"red\", linestyle=\"--\", label=\"P arrival\")\n",
    "\n",
    "if s_arrival is not None:\n",
    "    s_shifted = s_arrival - start\n",
    "    if 0 <= s_shifted < input_wave.shape[-1]:\n",
    "        for ax in axes:\n",
    "            ax.axvline(s_shifted, color=\"green\", linestyle=\"--\", label=\"S arrival\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae128618274972",
   "metadata": {},
   "source": [
    "## Layer-by-Layer Feature Evolution\n",
    "\n",
    "In this plot, we visualize the full feature transformation pipeline through the U-Net:\n",
    "\n",
    "1. The original input waveform (Z/N/E channels),\n",
    "2. Each intermediate layer (encoder stages, bottleneck, decoder stages),\n",
    "3. The final prediction compared to the true soft labels.\n",
    "\n",
    "All layers are plotted on the same time axis and overlaid with P and S wave arrival times. This view illustrates how temporal patterns are captured, abstracted, and reconstructed across the network hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7d1cdcdb5c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# --- 1. Get a test window that includes arrivals ---\n",
    "start = 5000\n",
    "sample = test_generator[0]\n",
    "waveform = sample[\"X\"][:, start:start+3001]\n",
    "true_labels = sample[\"y\"][:, start:start+3001]\n",
    "meta = sample.get(\"meta\", test.get_sample(0)[1])\n",
    "\n",
    "x = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "features = model.forward_intermediate(x)\n",
    "\n",
    "# --- 2. Extract input/prediction ---\n",
    "input_wave = features[\"input\"].squeeze().cpu().detach().numpy()\n",
    "prediction = features[\"output\"].squeeze().cpu().detach().numpy()\n",
    "\n",
    "# --- 3. Collect intermediate layers (enc*, bottleneck, dec*) ---\n",
    "layer_keys = [k for k in features.keys() if k.startswith(\"enc\") or k == \"bottleneck\" or k.startswith(\"dec\")]\n",
    "layer_keys = sorted(layer_keys, key=lambda k: (\"enc\" not in k, \"bottleneck\" not in k, k))  # enc1, enc2, ..., bottleneck, dec1, ...\n",
    "\n",
    "# --- 4. Create subplots ---\n",
    "n_rows = 2 + len(layer_keys)  # input + all layers + output\n",
    "fig, axes = plt.subplots(n_rows, 1, figsize=(14, 3 * n_rows), sharex=True)\n",
    "\n",
    "# --- 5. Plot input waveform ---\n",
    "for i in range(3):\n",
    "    axes[0].plot(input_wave[i] + i * 2, label=f\"Channel {['Z', 'N', 'E'][i]}\")\n",
    "axes[0].set_title(\"Input Waveform\")\n",
    "axes[0].legend()\n",
    "\n",
    "# --- 6. Plot all intermediate layers with rescaled extent ---\n",
    "for i, key in enumerate(layer_keys):\n",
    "    fmap = features[key].squeeze().cpu().detach().numpy()\n",
    "    extent = [0, input_wave.shape[-1], 0, fmap.shape[0]]\n",
    "    axes[i+1].imshow(fmap, aspect=\"auto\", cmap=\"viridis\", extent=extent)\n",
    "    axes[i+1].set_title(f\"{key}\")\n",
    "    axes[i+1].set_ylabel(\"Channels\")\n",
    "\n",
    "# --- 7. Plot prediction vs. true labels ---\n",
    "labels = [\"P\", \"S\", \"Noise\"]\n",
    "for i in range(3):\n",
    "    axes[-1].plot(prediction[i], label=f\"Pred {labels[i]}\", linestyle='-')\n",
    "    axes[-1].plot(true_labels[i], label=f\"True {labels[i]}\", linestyle='--', alpha=0.5)\n",
    "axes[-1].set_title(\"Prediction vs. True Labels\")\n",
    "axes[-1].legend()\n",
    "axes[-1].set_xlabel(\"Time (samples)\")\n",
    "\n",
    "# --- 8. Add vertical P and S arrivals to all plots ---\n",
    "p_arrival = meta.get(\"trace_P_arrival_sample\")\n",
    "s_arrival = meta.get(\"trace_S_arrival_sample\")\n",
    "\n",
    "if p_arrival is not None:\n",
    "    p_shifted = p_arrival - start\n",
    "    if 0 <= p_shifted < input_wave.shape[-1]:\n",
    "        for ax in axes:\n",
    "            ax.axvline(p_shifted, color=\"red\", linestyle=\"--\", label=\"P arrival\")\n",
    "\n",
    "if s_arrival is not None:\n",
    "    s_shifted = s_arrival - start\n",
    "    if 0 <= s_shifted < input_wave.shape[-1]:\n",
    "        for ax in axes:\n",
    "            ax.axvline(s_shifted, color=\"green\", linestyle=\"--\", label=\"S arrival\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730f8a832689d4c6",
   "metadata": {},
   "source": [
    "## ✅ Conclusion\n",
    "\n",
    "In this notebook, we implemented and visualized a U-Net model for seismic phase picking — a critical task in seismology for detecting P and S wave arrivals in continuous waveform data.\n",
    "\n",
    "### 🧠 What We Did:\n",
    "- Built a 1D U-Net architecture inspired by [PhaseNet](https://github.com/wayneweiqiang/PhaseNet), with skip connections and encoder-decoder structure.\n",
    "- Visualized **intermediate activations** to better understand how features evolve through the network.\n",
    "- Ran the model on real/test waveform windows and compared predicted probabilities with ground-truth labels.\n",
    "- Highlighted arrival times and validated that the model captures key temporal features across channels.\n",
    "\n",
    "### 📊 What We Learned:\n",
    "- The U-Net is capable of localizing subtle waveform changes across multiple channels.\n",
    "- Intermediate feature maps provide insight into what the network is learning at different stages (e.g., low-level vs. abstract features).\n",
    "- Well-aligned predictions with arrival times demonstrate strong temporal sensitivity.\n",
    "\n",
    "### 🧭 Next Steps:\n",
    "- Move to the **Evaluation Notebook** where we:\n",
    "  - Run the model over the full test set\n",
    "  - Compute metrics like precision, and recall\n",
    "  - Visualize confusion matrices and timing accuracy\n",
    "- Try training the model from scratch on custom datasets (e.g., regional catalogs or GNSS-derived events).\n",
    "- Add uncertainty estimation or ensemble techniques to improve robustness.\n",
    "\n",
    "> 🚀 This model is a strong baseline for real-time or post-event seismic analysis — and we’re just getting started!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
